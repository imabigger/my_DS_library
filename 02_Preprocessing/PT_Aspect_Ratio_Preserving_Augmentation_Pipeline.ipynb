{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294c6650",
   "metadata": {},
   "source": [
    "# Title: Aspect_Ratio_Preserving_Augmentation_Pipeline\n",
    "## Description: 이미지의 가로세로 비율을 유지하며 정사각형으로 패딩(Padding)한 후 리사이즈하는 전처리 기법과, 일반화 성능을 높이는 GridDropout 등의 증강 파이프라인.\n",
    "## Input: \n",
    " - image (numpy array): OpenCV로 로드된 이미지 (H, W, C)\n",
    " - cfg (dict): 이미지 사이즈(IMG_SIZE) 등이 정의된 설정 딕셔너리\n",
    "## Output: \n",
    " - augmented_image (tensor): 모델 입력용 정규화 및 증강된 텐서\n",
    "## Check Point: \n",
    " - `albumentations` 라이브러리 필요.\n",
    " - `PadSquare`는 `ImageOnlyTransform`을 상속받아 커스텀 구현됨.\n",
    "\n",
    " ![패딩 예시](/workspaces/my_DS_recipe_book/02_Preprocessing/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07152f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "# [Block 1] Custom Transform: 비율 유지 패딩 (PadSquare)\n",
    "class PadSquare(ImageOnlyTransform):\n",
    "    \"\"\"\n",
    "    이미지를 리사이즈하기 전, 원본 비율을 유지하기 위해\n",
    "    짧은 변을 기준으로 부족한 영역을 검은색(0)으로 채워 정사각형을 만드는 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, border_mode=0, value=0, always_apply=False, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.border_mode = border_mode\n",
    "        self.value = value\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        h, w, c = image.shape\n",
    "        max_dim = max(h, w)\n",
    "        \n",
    "        # 정사각형을 만들기 위해 필요한 패딩 계산 ( 각 방향별로 균등하게 분배 )\n",
    "        pad_h = max_dim - h\n",
    "        pad_w = max_dim - w\n",
    "\n",
    "        top = pad_h // 2\n",
    "        bottom = pad_h - top\n",
    "        left = pad_w // 2\n",
    "        right = pad_w - left\n",
    "\n",
    "        # cv2.copyMakeBorder를 이용해 상하좌우 패딩 적용\n",
    "        image = cv2.copyMakeBorder(\n",
    "            image, top, bottom, left, right,\n",
    "            cv2.BORDER_CONSTANT, value=self.value\n",
    "        )\n",
    "        return image\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('border_mode', 'value')\n",
    "\n",
    "# [Block 2] Augmentation Pipeline Definition\n",
    "def get_transforms(mode='train', img_size=224):\n",
    "    \"\"\"\n",
    "    학습 및 추론용 증강 파이프라인 생성\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            # 1. 비율 유지 패딩 (가장 먼저 적용)\n",
    "            PadSquare(value=(0, 0, 0)),\n",
    "            \n",
    "            # 2. Scale Invariance 학습을 위한 Random Crop\n",
    "            # 작은 물체도 학습할 수 있도록 다양한 스케일로 자른 후 리사이즈\n",
    "            A.RandomResizedCrop(\n",
    "                size=(img_size, img_size), \n",
    "                scale=(0.3, 1.0), \n",
    "                ratio=(0.9, 1.1), \n",
    "                p=1.0\n",
    "            ),\n",
    "            \n",
    "            # 3. 기하학적 변환 (Affine, Rotate, Flip)\n",
    "            A.Affine(scale=(0.9, 1.1), translate_percent=(0.05, 0.05), shear=(-5, 5), p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            \n",
    "            # 4. 픽셀값 변환 (Brightness)\n",
    "            A.RandomBrightnessContrast(limit=0.15, p=0.5),\n",
    "            \n",
    "            # 5. 정규화 (ImageNet 통계량)\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            \n",
    "            # 6. GridDropout: 물체의 일부분을 가려 강건함(Robustness) 향상\n",
    "            A.GridDropout(ratio=0.2, unit_size_min=5, p=0.5),\n",
    "            \n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif mode == 'test':\n",
    "        return A.Compose([\n",
    "            PadSquare(value=(0, 0, 0)), # 테스트 시에도 동일하게 비율 유지\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6d30d",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "1. **파이프라인 생성**: `train_transform = get_transforms(mode='train', img_size=224)` 형태로 호출하여 사용합니다.\n",
    "2. **Dataset 적용**: PyTorch `Dataset` 클래스의 `__getitem__` 메서드 내에서 다음과 같이 적용합니다.\n",
    "    ```python\n",
    "    if self.transforms:\n",
    "        image = self.transforms(image=image)['image']\n",
    "    ```\n",
    "\n",
    "## Troubleshooting\n",
    "- **패딩 색상(value)**: 기본값은 검은색 `(0,0,0)`입니다. 만약 배경이 흰색인 데이터라면 `value=(255,255,255)`로 변경해야 모델이 경계선을 오인하지 않습니다.\n",
    "- **RandomResizedCrop**: `scale=(0.3, 1.0)`은 이미지가 최소 30% 크기까지 줌인(Zoom-in) 될 수 있음을 의미합니다. [cite_start]데이터셋의 물체가 너무 크거나 작다면 이 범위를 조절하세요[cite: 10]."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
